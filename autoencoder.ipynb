{"nbformat":4,"nbformat_minor":4,"metadata":{"notebookPath":"thesising_autoencoder (3).ipynb","accelerator":"GPU","language_info":{"file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"notebookId":"0d05507c-d881-4083-b2de-fbbb988dcf59","colab":{"name":"thesising_autoencoder.ipynb","provenance":[],"collapsed_sections":["txBu9cl_VDuN"]},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"markdown","source":"### Imports","metadata":{"cellId":"27mrfop44vcxbp2koz1sab","id":"txBu9cl_VDuN"}},{"cell_type":"code","source":"from IPython.display import clear_output","metadata":{"id":"5mlTSAn4VLxH","cellId":"6vdjrg1cutpsdy78as202m","trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"%pip install -q path.py\n%pip install -q pytorch3d\n# https://github.com/facebookresearch/pifuhd/issues/77\n%pip install -q 'torch==1.6.0+cu101' -f https://download.pytorch.org/whl/torch_stable.html\n%pip install -q 'torchvision==0.7.0+cu101' -f https://download.pytorch.org/whl/torch_stable.html\n%pip install -q 'pytorch3d==0.2.5'\n%pip install -q Ninja\nclear_output()","metadata":{"id":"X8HRuNuIUKCs","cellId":"nd1k91qqlxaxz8ar5u4ycl","trusted":true},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import numpy as np\nimport math\nimport random\nimport os\nimport torch\nimport scipy.spatial.distance\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torchvision import transforms, utils\nfrom torch import optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nimport pytorch3d\n\nimport plotly.graph_objects as go\nimport plotly.express as px\n\nfrom path import Path\n\nfrom pytorch3d.loss import chamfer\n\nrandom.seed = 42","metadata":{"id":"eGZivZ4ATpOe","cellId":"f3xpj95qcz6u64ao5sp2e","trusted":true},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter","metadata":{"cellId":"svdaw8gx1xj4pmg2vssvf","trusted":true},"outputs":[],"execution_count":66},{"cell_type":"code","source":"!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip # /ModelNet40.zip - 40 classes\n!unzip -q ModelNet10.zip\n\npath = Path(\"ModelNet10\")\n\nfolders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n\nclear_output()\nclasses = {folder: i for i, folder in enumerate(folders)}\n# classes","metadata":{"id":"3fMK1k61UPNC","cellId":"pxl0g7d70gmn973436w0gm","trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"#!g1.1\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"outputId":"f39c6c41-fb3f-4ae8-e1db-74d7998c1c52","id":"S8r6OyS6-0lY","cellId":"o4nnd7okzadepakmifutkh","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"def init_weights(m):\n    if isinstance(m, nn.Linear):\n        torch.nn.init.xavier_uniform_(m.weight)\n        m.bias.data.fill_(0.1)","metadata":{"id":"RPnuR1Y86LfX","cellId":"4tusyi27dp9mb9jndpo6wj","trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"from enum import Enum\nclass DecoderType(Enum):\n    ORIGINAL = 1\n    INCREASE_POINTS = 2\n    INCREASE_CHANNELS = 3\n    \nclass DataType(Enum):\n    AUG_PRE = 1 # augmentation during training\n    AUG_DUR = 2\n    AUG_BOTH = 3","metadata":{"cellId":"t40j6tlm7gn6n3s6y7icm","trusted":true},"outputs":[],"execution_count":69},{"cell_type":"code","source":"# all augmentations before training\n# datatype = DataType.AUG_BEROFE\ntrainloader_pre = torch.load('dataloaders/dataloaders_beds_pre/trainloader.pth')\nvalidloader_pre = torch.load('dataloaders/dataloaders_beds_pre/validloader.pth')\n\n# all augmentations during training\n# datatype = DataType.AUG_DURING\ntrainloader_dur = torch.load('dataloaders/dataloaders_beds_dur/trainloader.pth')\nvalidloader_dur = torch.load('dataloaders/dataloaders_beds_dur/validloader.pth') \n\n# static (before training) augmentations + dynamic (during training) augmentations\n# datatype = DataType.AUG_BOTH\ntrainloader_both = torch.load('dataloaders/dataloaders_beds_both/trainloader.pth')\nvalidloader_both = torch.load('dataloaders/dataloaders_beds_both/validloader.pth')","metadata":{"id":"bq3LKINV9kSG","cellId":"zg6pvw2o6fmgnv5is7qhzs","trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"class PointNetAE(nn.Module):\n    def __init__(self, num_points=1024, z_dim=100, decoder_type=DecoderType.ORIGINAL):\n        super(PointNetAE, self).__init__()\n        self.num_points = num_points\n        self.encoder = PointEncoder(num_points, z_dim=z_dim)\n\n        if decoder_type is DecoderType.INCREASE_POINTS:\n            self.decoder = PointDecoderPoints(num_points, z_dim=z_dim)\n        elif decoder_type is DecoderType.INCREASE_CHANNELS:\n            self.decoder = PointDecoderChannels(num_points, z_dim=z_dim)\n        else:\n            self.decoder = PointDecoderOriginal(num_points, z_dim=z_dim)\n\n        self.name = self.decoder.name\n\n    def reparameterize(self, mu, log_var):\n        std = torch.exp(log_var / 2)\n        eps = torch.randn_like(std)\n        return mu + std * eps\n\n    def forward(self, x):\n        x, mu, logvar = self.encoder(x)\n        # x = self.reparameterize(mu, logvar)\n        x = self.decoder(x)\n        return x\n\n\nclass PointEncoder(nn.Module):\n    def __init__(self, num_points, z_dim):\n        super(PointEncoder, self).__init__()\n        self.num_points = num_points\n        self.feature_dim = z_dim\n        self.convs = nn.Sequential(\n            nn.Conv1d(3, 64, 1),\n            nn.BatchNorm1d(64),\n            nn.ReLU(),\n            nn.Conv1d(64, 128, 1),\n            nn.BatchNorm1d(128),\n            nn.ReLU(),\n            nn.Conv1d(128, num_points, 1),\n            nn.BatchNorm1d(num_points),\n        )\n\n        self.dense = nn.Sequential(\n            nn.Linear(num_points, 512),\n            nn.ReLU(),\n            nn.Linear(512, self.feature_dim)\n        )\n\n        self.dense.apply(init_weights)\n\n        self.mu_fc = nn.Linear(self.feature_dim, z_dim)\n        self.log_var_fc = nn.Linear(self.feature_dim, z_dim)\n\n    def forward(self, x):\n        x = self.convs(x)\n        x, _ = torch.max(x, 2) # instead of maxpool\n        x = x.view(-1, self.num_points)\n        x = self.dense(x)\n        x_relu = torch.relu(x)\n        mu, log_var = self.mu_fc(x_relu), self.log_var_fc(x_relu)\n        return x, mu, log_var\n\n\n# ORIGINAL - all layers are linear\nclass PointDecoderOriginal(nn.Module):\n    def __init__(self, num_points, z_dim):\n        super(PointDecoderOriginal, self).__init__()\n        self.num_points = num_points\n        self.name = 'original'\n        self.dense_layers = nn.Sequential(\n            nn.Linear(z_dim, 256),\n            nn.Dropout(0.1),\n            nn.ReLU(),\n            nn.Linear(256, 512),\n            nn.Dropout(0.2),\n            nn.ReLU(),\n            nn.Linear(512, num_points),\n            nn.Dropout(0.3),\n            nn.Linear(num_points, num_points*3),\n            nn.Tanh()\n        )\n        self.dense_layers.apply(init_weights)\n\n    def forward(self, x):\n        batchsize = x.size()[0]\n        x = self.dense_layers(x)\n        x = x.view(batchsize, 3, self.num_points)\n        return x\n\n\n# USE CONV1D TO INCREASE NUMBER OF POINTS (z_dim -> 1024)\n# class PointDecoderPoints(nn.Module):\n#     def __init__(self, num_points, z_dim):\n#         super(PointDecoderPoints, self).__init__()\n#         self.num_points = num_points\n#         self.z_dim = z_dim\n#         self.name = f'model_conv1d_{z_dim}_{num_points}'\n#         self.conv_layers = nn.Sequential(\n#             nn.Conv1d(z_dim, 256, 1),\n#             nn.BatchNorm1d(256),\n#             nn.ReLU(),\n#             nn.Conv1d(256, 512, 1),\n#             nn.BatchNorm1d(512),\n#             nn.ReLU(),\n#             nn.Conv1d(512, num_points, 1),\n#             nn.BatchNorm1d(num_points),\n#             nn.ReLU()\n#         )\n#         self.linear = nn.Sequential(\n#             nn.Linear(num_points, num_points*3, 1),\n#             nn.Dropout(0.4),\n#             nn.Tanh()\n#         )\n#         self.linear.apply(init_weights)\n\n#     def forward(self, x):\n#         batchsize = x.size()[0]\n#         x = x.reshape(batchsize, self.z_dim, 1)\n#         x = self.conv_layers(x).reshape(batchsize, self.num_points)\n#         x = self.linear(x).reshape(batchsize, 3, self.num_points)\n#         return x\n\n\n# USE CONV1D TO INCREASE NUMBER OF DIMENSIONS (1 -> 3)\n# class PointDecoderChannels(nn.Module):\n#     def __init__(self, num_points, z_dim):\n#         super(PointDecoderChannels, self).__init__()\n#         self.num_points = num_points\n#         self.name = 'model_conv1d_1_3'\n#         self.dense_layers = nn.Sequential(\n#             nn.Linear(z_dim, 256),\n#             nn.Dropout(0.1),\n#             nn.ReLU(),\n#             nn.Linear(256, 512),\n#             nn.Dropout(0.2),\n#             nn.ReLU(),\n#             nn.Linear(512, num_points),\n#             nn.Dropout(0.3),\n#         )\n#         self.conv = nn.Sequential(\n#             nn.Conv1d(1, 3, 1),\n#             nn.Tanh()\n#         )\n#         self.dense_layers.apply(init_weights)\n\n#     def forward(self, x):\n#         batchsize = x.size()[0]\n#         x = self.dense_layers(x).reshape(batchsize, 1, self.num_points)\n#         x = self.conv(x)\n#         return x","metadata":{"id":"-Q7CBzlNr60x","cellId":"b6ind1hkqjh587cozktm42","trusted":true},"outputs":[],"execution_count":64},{"cell_type":"code","source":"encoder = PointEncoder(1024, 100)\ndecoder = PointDecoderOriginal(1024, 100)\nfor x, _ in beds_loader:\n    x = x.float().permute(0, 2, 1)\n    output, _, _ = encoder(x)\n    print(decoder(output).shape)\n    break","metadata":{"id":"Nx07t8XMnkAQ","cellId":"09e0lwsx33d43smfjyg1ccb","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"torch.Size([32, 3, 1024])\n"}],"execution_count":65},{"cell_type":"code","source":"def train_pcautoencoder(autoencoder, x, loss_func, optimizer):\n    '''\n    loss function must be chamfer distance\n    '''\n    optimizer.zero_grad()\n    x = x.float().to(device).permute(0, 2, 1)\n    output = autoencoder(x)\n    dist1, dist2 = loss_func(x, output)\n\n    try:\n        # dist2 might be None if x_normals and y_normals (args to loss_func) are None\n        loss = (torch.mean(dist1)) + (torch.mean(dist2))\n    except:\n        loss = (torch.mean(dist1))\n\n    loss.backward()\n    optimizer.step()\n\n    return loss.data.item()\n\n\ndef validate_pcautoencoder(autoencoder, x, loss_func):\n    '''\n    loss function must be chamfer distance\n    '''\n    with torch.no_grad():\n        x = x.float().to(device).permute(0, 2, 1)\n        output = autoencoder(x)\n        dist1, dist2 = loss_func(x, output)\n\n        try:\n            # dist2 might be None if x_normals and y_normals (args to loss_func) are None\n            loss = (torch.mean(dist1)) + (torch.mean(dist2))\n        except:\n            loss = (torch.mean(dist1))\n\n        return loss.data.item()","metadata":{"id":"kI_Dzvq80IcN","cellId":"tpaszdlu96dy8s2fn6ssdr","trusted":true},"outputs":[],"execution_count":31},{"cell_type":"code","source":"def train_with_chamfer_dist(autoencoder, loaders_type, loss_func, optimizer,\n                            train_func, validate_func, epochs=100, print_every_e=5, valid_every=5,\n                            scheduler=None, summary_writer=None, model_name='model'):\n    if loaders_type is DataType.AUG_PRE:\n        train_loader, valid_loader = trainloader_pre, validloader_pre\n    elif loaders_type is DataType.AUG_DUR:\n        train_loader, valid_loader = trainloader_dur, validloader_dur\n    else:\n        train_loader, valid_loader = trainloader_both, validloader_both\n\n    autoencoder.train()\n    for epoch in range(1, epochs+1):\n        losses = []\n        for x, _ in train_loader:\n            loss = train_func(autoencoder, x, loss_func, optimizer)\n            losses.append(loss)\n        if summary_writer is not None:\n            summary_writer.add_scalar(f'{model_name}/train/loss', np.mean(losses), epoch)\n        if scheduler:\n            scheduler.step()\n\n        if epoch % print_every_e == 0 or epoch == 1:\n            print(f'{epoch}:\\ttrain loss: {np.mean(losses)}')\n        if epoch % valid_every == 0:\n            valid_losses = []\n            for x, _ in valid_loader:\n                valid_loss = validate_func(autoencoder, x, loss_func)\n                valid_losses.append(valid_loss)\n            if summary_writer is not None:\n                summary_writer.add_scalar(f'{model_name}/valid/loss', np.mean(valid_losses), epoch)\n            print(f'\\tvalidation loss: {np.mean(valid_losses)}')","metadata":{"id":"JRxLRg17H701","cellId":"bkjsfvpeg6ol0x4jwnlx8","trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"writer = SummaryWriter()","metadata":{"cellId":"i81ucbbskskuot5y79xnoa"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\n# CHANGE DECODER TYPE\npc_autoencoder = PointNetAE(num_points=1024, z_dim=100, decoder_type=DecoderType.Original)\npc_autoencoder.to(device)\n\noptimizer = optim.AdamW(pc_autoencoder.parameters(), lr=0.0009, betas=(0.8, 0.8))\n# optimizer = optim.SGD(pc_autoencoder.parameters(), lr=0.01)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2500, gamma=0.5)\nloss_func = chamfer.chamfer_distance\n\n# CHANGE DATA TYPE\ntrain_with_chamfer_dist(pc_autoencoder, loaders_type=DataType.AUG_PRE, loss_func=loss_func,\n                        valid_loader=beds_loader_valid, train_func=train_pcautoencoder, validate_func=validate_pcautoencoder,\n                        epochs=10000, print_every_e=100, valid_every=100, scheduler=scheduler, summary_writer=writer, \n                        model_name=pc_autoencoder.name)","metadata":{"outputId":"3c58dca6-fa0f-465a-ed8a-de072186193d","jupyter":{"outputs_hidden":true},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":636},"collapsed":true,"id":"RDaoff7gz9gz","cellId":"2g4fs2vk3q861bbl9l5spe"},"outputs":[{"output_type":"stream","name":"stdout","text":"1:\ttrain loss: 339.8019332885742\n100:\ttrain loss: 124.65575838088989\n\tvalidation loss: 123.31191507975261\n200:\ttrain loss: 124.54345321655273\n\tvalidation loss: 123.2471440633138\n300:\ttrain loss: 124.54922294616699\n\tvalidation loss: 123.24136861165364\n400:\ttrain loss: 124.55694103240967\n\tvalidation loss: 123.35435994466145\n500:\ttrain loss: 124.47421646118164\n\tvalidation loss: 123.30106862386067\n600:\ttrain loss: 124.6281590461731\n\tvalidation loss: 122.83753204345703\n700:\ttrain loss: 124.43552923202515\n\tvalidation loss: 122.8958511352539\n800:\ttrain loss: 124.52057123184204\n\tvalidation loss: 123.06599680582683\n900:\ttrain loss: 124.43160152435303\n\tvalidation loss: 123.08112335205078\n1000:\ttrain loss: 124.48707723617554\n\tvalidation loss: 122.97868347167969\n1100:\ttrain loss: 124.42672157287598\n\tvalidation loss: 122.91610463460286\n1200:\ttrain loss: 124.24827289581299\n\tvalidation loss: 123.41895294189453\n1300:\ttrain loss: 124.3877854347229\n\tvalidation loss: 122.91690317789714\n1400:\ttrain loss: 124.5795545578003\n\tvalidation loss: 123.10669962565105\n1500:\ttrain loss: 124.38450956344604\n\tvalidation loss: 123.02288818359375\n"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)","\u001B[0;32m<ipython-input-1-70f4d3fe766e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m train_with_chamfer_dist(pc_autoencoder, beds_loader, loss_func, optimizer, valid_loader=beds_loader_valid,\n\u001B[0;32m---> 11\u001B[0;31m                         train_func=train_pcautoencoder, validate_func=validate_pcautoencoder, epochs=10000, print_every_e=100, valid_every=100, scheduler=scheduler)\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m<ipython-input-4-333e7a5897f7>\u001B[0m in \u001B[0;36mtrain_with_chamfer_dist\u001B[0;34m(autoencoder, train_loader, loss_func, optimizer, valid_loader, train_func, validate_func, epochs, print_every_e, valid_every, scheduler)\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    361\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    362\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 363\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    364\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    365\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    972\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    973\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_shutdown\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 974\u001B[0;31m             \u001B[0midx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    975\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[0;34m-=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    976\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    939\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    940\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 941\u001B[0;31m                 \u001B[0msuccess\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_try_get_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    942\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0msuccess\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    943\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    777\u001B[0m         \u001B[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    778\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 779\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data_queue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    780\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    781\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    102\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mblock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m                     \u001B[0mtimeout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdeadline\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmonotonic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 104\u001B[0;31m                     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    105\u001B[0m                         \u001B[0;32mraise\u001B[0m \u001B[0mEmpty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m                 \u001B[0;32melif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001B[0m in \u001B[0;36mpoll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    255\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_closed\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    256\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_readable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 257\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    258\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    259\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__enter__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001B[0m in \u001B[0;36m_poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    412\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    413\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_poll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 414\u001B[0;31m         \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    415\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mbool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    416\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/multiprocessing/connection.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    919\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    920\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 921\u001B[0;31m                 \u001B[0mready\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mselector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    922\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    923\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfileobj\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevents\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/selectors.py\u001B[0m in \u001B[0;36mselect\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    413\u001B[0m         \u001B[0mready\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    414\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 415\u001B[0;31m             \u001B[0mfd_event_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_selector\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpoll\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    416\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mInterruptedError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    417\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mready\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mKeyboardInterrupt\u001B[0m: "]}],"execution_count":53},{"cell_type":"code","source":"#!g1.1\ntorch.save(pc_autoencoder.state_dict(), 'MODEL_NAME.pth')","metadata":{"id":"1N2WQNlYd46W","cellId":"2vhgj9x3ygipgn1v1tfd0i","trusted":true},"outputs":[],"execution_count":45}]}