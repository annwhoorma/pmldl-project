{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thesising_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "txBu9cl_VDuN",
        "JmWkK4xdhp_P"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txBu9cl_VDuN"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mlTSAn4VLxH"
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHq_qriVqSjf",
        "outputId": "c7912cb2-7216-45f5-ce06-a5cca7a0c486"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8HRuNuIUKCs"
      },
      "source": [
        "!pip install -q path.py\n",
        "!pip install -q pytorch3d\n",
        "# https://github.com/facebookresearch/pifuhd/issues/77\n",
        "!pip install -q 'torch==1.6.0+cu101' -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -q 'torchvision==0.7.0+cu101' -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -q 'pytorch3d==0.2.5'\n",
        "!pip install -q Ninja\n",
        "clear_output()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGZivZ4ATpOe"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import scipy.spatial.distance\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms, utils\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pytorch3d\n",
        "\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "from path import Path\n",
        "\n",
        "from pytorch3d.loss import chamfer\n",
        "\n",
        "random.seed = 42"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fMK1k61UPNC"
      },
      "source": [
        "!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip # /ModelNet40.zip - 40 classes\n",
        "!unzip -q ModelNet10.zip\n",
        "\n",
        "path = Path(\"ModelNet10\")\n",
        "\n",
        "folders = [dir for dir in sorted(os.listdir(path)) if os.path.isdir(path/dir)]\n",
        "\n",
        "clear_output()\n",
        "classes = {folder: i for i, folder in enumerate(folders)}\n",
        "# classes"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxatJe9jG9Be"
      },
      "source": [
        "#### Imports from helping.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPCR51Y7G_BO"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1CVwVxdfUfP6TRcVUjjJvQeRcgCGcnSO_\n",
        "from helping import *\n",
        "clear_output()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmWkK4xdhp_P"
      },
      "source": [
        "### Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blZorZZ26O1q"
      },
      "source": [
        "trainloader_pre = torch.load('drive/MyDrive/Thesis/dataloaders/final/dataloader_beds_pre/trainloader.pth')\n",
        "validloader_pre = torch.load('drive/MyDrive/Thesis/dataloaders/final/dataloader_beds_pre/validloader.pth')\n",
        "\n",
        "trainloader_both = torch.load('drive/MyDrive/Thesis/dataloaders/final/dataloader_beds_both/trainloader.pth')\n",
        "validloader_both = torch.load('drive/MyDrive/Thesis/dataloaders/final/dataloader_beds_both/validloader.pth')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8r6OyS6-0lY",
        "outputId": "c8338d8a-135d-4fd1-9153-849fc0a98cd0"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbUjuiyfAbTD"
      },
      "source": [
        "## Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi4jJ9jSwPPx"
      },
      "source": [
        "### PCAutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPnuR1Y86LfX"
      },
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ooNdMk-_7RX"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from enum import Enum\n",
        "class DecoderType(Enum):\n",
        "    ORIGINAL = 1\n",
        "    INCREASE_POINTS = 2\n",
        "    INCREASE_CHANNELS = 3\n",
        "    \n",
        "class DataType(Enum):\n",
        "    AUG_PRE = 1 # augmentation during training\n",
        "    AUG_DUR = 2\n",
        "    AUG_BOTH = 3"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q7CBzlNr60x"
      },
      "source": [
        "class PointNetAE(nn.Module):\n",
        "    def __init__(self, num_points=1024, z_dim=100, decoder_type=DecoderType.ORIGINAL):\n",
        "        super(PointNetAE, self).__init__()\n",
        "        self.num_points = num_points\n",
        "\n",
        "        self.encoder = PointEncoder(num_points, z_dim=z_dim)\n",
        "        if decoder_type is DecoderType.INCREASE_POINTS:\n",
        "            self.decoder = PointDecoderPoints(num_points, z_dim=z_dim)\n",
        "        elif decoder_type is DecoderType.INCREASE_CHANNELS:\n",
        "            self.decoder = PointDecoderChannels(num_points, z_dim=z_dim)\n",
        "        else:\n",
        "            self.decoder = PointDecoderOriginal(num_points, z_dim=z_dim)\n",
        "\n",
        "        self.name = self.decoder.name\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(log_var / 2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + std * eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, mu, logvar = self.encoder(x)\n",
        "        # x = self.reparameterize(mu, logvar)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class PointEncoder(nn.Module):\n",
        "    def __init__(self, num_points, z_dim):\n",
        "        super(PointEncoder, self).__init__()\n",
        "        self.num_points = num_points\n",
        "        self.feature_dim = z_dim\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv1d(3, 64, 1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(64, 128, 1),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(128, num_points, 1),\n",
        "            nn.BatchNorm1d(num_points),\n",
        "        )\n",
        "\n",
        "        self.dense = nn.Sequential(\n",
        "            nn.Linear(num_points, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, self.feature_dim)\n",
        "        )\n",
        "\n",
        "        self.dense.apply(init_weights)\n",
        "\n",
        "        self.mu_fc = nn.Linear(self.feature_dim, z_dim)\n",
        "        self.log_var_fc = nn.Linear(self.feature_dim, z_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        x, _ = torch.max(x, 2) # instead of maxpool\n",
        "        x = x.view(-1, self.num_points)\n",
        "        x = self.dense(x)\n",
        "        x_relu = torch.relu(x)\n",
        "        mu, log_var = self.mu_fc(x_relu), self.log_var_fc(x_relu)\n",
        "        return x, mu, log_var\n",
        "\n",
        "\n",
        "'''\n",
        "use only dense layers in decoder\n",
        "dec1_aug1_1024_48.pt\n",
        "dec1_aug3_1024_48.pt\n",
        "'''\n",
        "class PointDecoderOriginal(nn.Module):\n",
        "    def __init__(self, num_points, z_dim):\n",
        "        super(PointDecoderOriginal, self).__init__()\n",
        "        self.name = f'model_dense'\n",
        "        self.num_points = num_points\n",
        "        self.dense_layers = nn.Sequential(\n",
        "            nn.Linear(z_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_points),\n",
        "            nn.Linear(num_points, num_points*3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.dense_layers.apply(init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        x = self.dense_layers(x)\n",
        "        x = x.view(batchsize, 3, self.num_points)\n",
        "        return x\n",
        "\n",
        "'''\n",
        "apply Conv1d to increase dimensionality (1 -> 3), 3: x, y, z\n",
        "'''\n",
        "class PointDecoderChannels(nn.Module):\n",
        "    def __init__(self, num_points, z_dim):\n",
        "        super(PointDecoderChannels, self).__init__()\n",
        "        self.num_points = num_points\n",
        "        self.name = 'model_conv1d_channels'\n",
        "        self.dense_layers = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.Dropout(0.05),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.Dropout(0.05),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_points),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(1, 3, 1),\n",
        "            nn.BatchNorm1d(3),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.dense_layers.apply(init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        x = self.dense_layers(x).reshape(batchsize, 1, self.num_points)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "'''\n",
        "apply Conv1d to increase number of points (to 1024)\n",
        "'''\n",
        "class PointDecoderPoints(nn.Module):\n",
        "    def __init__(self, num_points, z_dim):\n",
        "        super(PointDecoderPoints, self).__init__()\n",
        "        self.num_points = num_points\n",
        "        self.z_dim = z_dim\n",
        "        self.name = f'model_conv1d_points'\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(100, 256, 1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(256, num_points, 1),\n",
        "            nn.BatchNorm1d(num_points),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.dense_layers = nn.Sequential(\n",
        "            nn.Linear(num_points, num_points*3),\n",
        "            nn.Dropout(0.05),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.dense_layers.apply(init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        x = x.reshape(batchsize, self.z_dim, 1)\n",
        "        x = self.conv(x).reshape(batchsize, self.num_points)\n",
        "        x = self.dense_layers(x)\n",
        "        x = x.reshape(batchsize, 3, self.num_points)\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI_Dzvq80IcN"
      },
      "source": [
        "def train_pcautoencoder(autoencoder, x, loss_func, optimizer):\n",
        "    '''\n",
        "    loss function must be chamfer distance\n",
        "    '''\n",
        "    optimizer.zero_grad()\n",
        "    x = x.float().to(device).permute(0, 2, 1)\n",
        "    output = autoencoder(x)\n",
        "    dist1, dist2 = loss_func(x, output)\n",
        "\n",
        "    try:\n",
        "        # dist2 might be None if x_normals and y_normals (args to loss_func) are None\n",
        "        loss = (torch.mean(dist1)) + (torch.mean(dist2))\n",
        "    except:\n",
        "        loss = (torch.mean(dist1))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.data.item()\n",
        "\n",
        "\n",
        "def validate_pcautoencoder(autoencoder, x, loss_func):\n",
        "    '''\n",
        "    loss function must be chamfer distance\n",
        "    '''\n",
        "    with torch.no_grad():\n",
        "        x = x.float().to(device).permute(0, 2, 1)\n",
        "        output = autoencoder(x)\n",
        "        dist1, dist2 = loss_func(x, output)\n",
        "\n",
        "        try:\n",
        "            # dist2 might be None if x_normals and y_normals (args to loss_func) are None\n",
        "            loss = (torch.mean(dist1)) + (torch.mean(dist2))\n",
        "        except:\n",
        "            loss = (torch.mean(dist1))\n",
        "\n",
        "        return loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRxLRg17H701"
      },
      "source": [
        "def train_with_chamfer_dist(autoencoder, loaders_type, loss_func, optimizer,\n",
        "                            train_func, validate_func, epochs=100, print_every_e=5, valid_every=5,\n",
        "                            scheduler=None, summary_writer=None, model_name='model'):\n",
        "    if loaders_type is DataType.AUG_PRE:\n",
        "        train_loader, valid_loader = trainloader_pre, validloader_pre\n",
        "    elif loaders_type is DataType.AUG_DUR:\n",
        "        train_loader, valid_loader = trainloader_dur, validloader_dur\n",
        "    else:\n",
        "        train_loader, valid_loader = trainloader_both, validloader_both\n",
        "\n",
        "    autoencoder.train()\n",
        "    for epoch in range(1, epochs+1):\n",
        "        losses = []\n",
        "        for x, _ in train_loader:\n",
        "            loss = train_func(autoencoder, x, loss_func, optimizer)\n",
        "            losses.append(loss)\n",
        "        if summary_writer is not None:\n",
        "            summary_writer.add_scalar(f'{model_name}/train/loss', np.mean(losses), epoch)\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        if epoch % print_every_e == 0 or epoch == 1:\n",
        "            print(f'{epoch}:\\ttrain loss: {np.mean(losses)}')\n",
        "        if epoch % valid_every == 0:\n",
        "            valid_losses = []\n",
        "            for x, _ in valid_loader:\n",
        "                valid_loss = validate_func(autoencoder, x, loss_func)\n",
        "                valid_losses.append(valid_loss)\n",
        "            if summary_writer is not None:\n",
        "                summary_writer.add_scalar(f'{model_name}/valid/loss', np.mean(valid_losses), epoch)\n",
        "            print(f'\\tvalidation loss: {np.mean(valid_losses)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkWba-DtB3GW"
      },
      "source": [
        "def save_model(pca, loaders_type, batchsize=48):\n",
        "    if loaders_type is DataType.AUG_PRE:\n",
        "        aug = 'pre'\n",
        "    elif loaders_type is DataType.AUG_DUR:\n",
        "        aug = 'dur'\n",
        "    else:\n",
        "        aug = 'both'\n",
        "    torch.save(pca, f'{pca.name}_{aug}_{batchsize}.pt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niMYd-wCCEUv"
      },
      "source": [
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDaoff7gz9gz"
      },
      "source": [
        "pc_autoencoder = PointNetAE(num_points=1024, z_dim=100)\n",
        "pc_autoencoder.to(device)\n",
        "\n",
        "optimizer = optim.AdamW(pc_autoencoder.parameters(), lr=0.001, betas=(0.8, 0.8))\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.5)\n",
        "loss_func = chamfer.chamfer_distance\n",
        "\n",
        "\n",
        "train_with_chamfer_dist(pc_autoencoder, loaders_type=DataType.AUG_PRE, loss_func=loss_func, optimizer=optimizer,\n",
        "                        train_func=train_pcautoencoder, validate_func=validate_pcautoencoder,\n",
        "                        epochs=4000, print_every_e=50, valid_every=100, scheduler=scheduler, summary_writer=writer, \n",
        "                        model_name=pc_autoencoder.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td9iVLtEPI5U"
      },
      "source": [
        "# save_model(pc_autoencoder, loaders_type=DataType.AUG_BOTH)\n",
        "# !cp -r runs drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_ZahPBQvCYr",
        "outputId": "c25af0c1-462e-4530-91fc-8a8a747be88e"
      },
      "source": [
        "!ls drive/MyDrive/Thesis/models/dec1\\ aug\\ pre\\ 48"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_dense_pre_48.pt  runs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFo82E5e9buC"
      },
      "source": [
        "all_model_paths = [\n",
        "                   'drive/MyDrive/Thesis/models/dec1 aug pre 48/model_dense_pre_48.pt',\n",
        "                   'drive/MyDrive/Thesis/models/dec1 aug both 48/model_dense_both_48.pt',\n",
        "                   'drive/MyDrive/Thesis/models/dec3 aug pre 48/model_conv1d_points_pre_48.pt',\n",
        "                   'drive/MyDrive/Thesis/models/dec3 aug both 48/model_conv1d_points_both_48.pt'\n",
        "]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlhB9ZG8v4QQ"
      },
      "source": [
        "writer = SummaryWriter()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNl0r3ODxVcT"
      },
      "source": [
        "# !mv runs drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwrttFt126hQ"
      },
      "source": [
        "loaders_type = DataType.AUG_BOTH\n",
        "loss_func = chamfer.chamfer_distance\n",
        "batch_size = 48\n",
        "show_orig, show_res = False, False\n",
        "\n",
        "for model_path in all_model_paths:\n",
        "    model = torch.load(model_path)\n",
        "    model.eval()\n",
        "    model_name = model.name\n",
        "\n",
        "    loaders_type = DataType.AUG_BOTH if 'both' in model_path else DataType.AUG_PRE\n",
        "    if loaders_type is DataType.AUG_PRE:\n",
        "        train_loader, valid_loader = trainloader_pre, validloader_pre\n",
        "    elif loaders_type is DataType.AUG_DUR:\n",
        "        train_loader, valid_loader = trainloader_dur, validloader_dur\n",
        "    else:\n",
        "        train_loader, valid_loader = trainloader_both, validloader_both\n",
        "\n",
        "    for valid_num in range(batch_size):\n",
        "        two_losses = []\n",
        "        for train in [True, False]:\n",
        "            local_sample = None\n",
        "            for sample, _ in train_loader if train else valid_loader:\n",
        "                sample = sample.permute(0, 2, 1)\n",
        "                local_sample = sample[valid_num]\n",
        "                x, y, z = local_sample[:][0], local_sample[:][1], local_sample[:][2]\n",
        "                if show_orig:\n",
        "                    pcshow(x, y, z)\n",
        "                break\n",
        "            with torch.no_grad():\n",
        "                samplee = local_sample.unsqueeze(0).float().to(device)\n",
        "                out = model(samplee)\n",
        "            first = out[0].detach().cpu()\n",
        "            x, y, z = first[:][0], first[:][1], first[:][2]\n",
        "            loss = loss_func(first.unsqueeze(0).float(), local_sample.unsqueeze(0).float())[0].item()\n",
        "            two_losses.append(loss)\n",
        "            if show_res:\n",
        "                pcshow(x, y, z)\n",
        "        writer.add_scalar(f'{model_name}/{loaders_type}/train', two_losses[0], valid_num)\n",
        "        writer.add_scalar(f'{model_name}/{loaders_type}/valid', two_losses[1], valid_num)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
